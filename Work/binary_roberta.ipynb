{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E4a-fn49FVB7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.4.0\n",
            "  Using cached transformers-3.4.0-py3-none-any.whl (1.3 MB)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Using cached sentencepiece-0.1.97-cp310-cp310-macosx_10_9_x86_64.whl (1.2 MB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers==3.4.0) (2022.8.17)\n",
            "Requirement already satisfied: packaging in /Users/syeda/Library/Python/3.10/lib/python/site-packages (from transformers==3.4.0) (21.3)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers==3.4.0) (1.23.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers==3.4.0) (4.64.1)\n",
            "Collecting sacremoses\n",
            "  Using cached sacremoses-0.0.53-py3-none-any.whl\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers==3.4.0) (3.8.0)\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers==3.4.0) (2.28.1)\n",
            "Requirement already satisfied: protobuf in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers==3.4.0) (3.19.6)\n",
            "Collecting tokenizers==0.9.2\n",
            "  Using cached tokenizers-0.9.2.tar.gz (170 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/syeda/Library/Python/3.10/lib/python/site-packages (from packaging->transformers==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers==3.4.0) (1.26.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers==3.4.0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers==3.4.0) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers==3.4.0) (2022.6.15.1)\n",
            "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sacremoses->transformers==3.4.0) (1.16.0)\n",
            "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sacremoses->transformers==3.4.0) (1.1.0)\n",
            "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sacremoses->transformers==3.4.0) (8.1.3)\n",
            "Building wheels for collected packages: tokenizers\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[56 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m running bdist_wheel\n",
            "  \u001b[31m   \u001b[0m running build\n",
            "  \u001b[31m   \u001b[0m running build_py\n",
            "  \u001b[31m   \u001b[0m creating build\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-310\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-310/tokenizers\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/__init__.py -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-310/tokenizers/models\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/models/__init__.py -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers/models\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-310/tokenizers/decoders\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/decoders/__init__.py -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers/decoders\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-310/tokenizers/normalizers\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/normalizers/__init__.py -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers/normalizers\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-310/tokenizers/pre_tokenizers\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/pre_tokenizers/__init__.py -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers/pre_tokenizers\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-310/tokenizers/processors\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/processors/__init__.py -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers/processors\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-310/tokenizers/trainers\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/trainers/__init__.py -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers/trainers\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-universal2-cpython-310/tokenizers/implementations\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/byte_level_bpe.py -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers/implementations\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/sentencepiece_unigram.py -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers/implementations\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/sentencepiece_bpe.py -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers/implementations\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/base_tokenizer.py -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers/implementations\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/__init__.py -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers/implementations\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/char_level_bpe.py -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers/implementations\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/bert_wordpiece.py -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers/implementations\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/__init__.pyi -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/models/__init__.pyi -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers/models\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/decoders/__init__.pyi -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers/decoders\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/normalizers/__init__.pyi -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers/normalizers\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/pre_tokenizers/__init__.pyi -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers/pre_tokenizers\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/processors/__init__.pyi -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers/processors\n",
            "  \u001b[31m   \u001b[0m copying py_src/tokenizers/trainers/__init__.pyi -> build/lib.macosx-10.9-universal2-cpython-310/tokenizers/trainers\n",
            "  \u001b[31m   \u001b[0m running build_ext\n",
            "  \u001b[31m   \u001b[0m running build_rust\n",
            "  \u001b[31m   \u001b[0m cargo rustc --lib --message-format=json-render-diagnostics --manifest-path Cargo.toml --release -v --features pyo3/extension-module -- --crate-type cdylib -C link-args=-undefined dynamic_lookup -Wl,-install_name,@rpath/tokenizers.cpython-310-darwin.so\n",
            "  \u001b[31m   \u001b[0m warning: unused manifest key: target.x86_64-apple-darwin.rustflags\n",
            "  \u001b[31m   \u001b[0m     Updating crates.io index\n",
            "  \u001b[31m   \u001b[0m     Updating git repository `https://github.com/pyo3/rust-numpy/`\n",
            "  \u001b[31m   \u001b[0m     Updating git repository `https://github.com/n1t0/rayon-cond`\n",
            "  \u001b[31m   \u001b[0m  Downloading crates ...\n",
            "  \u001b[31m   \u001b[0m error: failed to download `rayon-core v1.10.1`\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m Caused by:\n",
            "  \u001b[31m   \u001b[0m   unable to get packages from source\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m Caused by:\n",
            "  \u001b[31m   \u001b[0m   failed to parse manifest at `/Users/syeda/.cargo/registry/src/github.com-1ecc6299db9ec823/rayon-core-1.10.1/Cargo.toml`\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m Caused by:\n",
            "  \u001b[31m   \u001b[0m   failed to parse the `edition` key\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m Caused by:\n",
            "  \u001b[31m   \u001b[0m   this version of Cargo is older than the `2021` edition, and only supports `2015` and `2018` editions.\n",
            "  \u001b[31m   \u001b[0m error: `cargo rustc --lib --message-format=json-render-diagnostics --manifest-path Cargo.toml --release -v --features pyo3/extension-module -- --crate-type cdylib -C 'link-args=-undefined dynamic_lookup -Wl,-install_name,@rpath/tokenizers.cpython-310-darwin.so'` failed with code 101\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build tokenizers\n",
            "\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
            "    extend(render(renderable, render_options))\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
            "    for render_output in iter_render:\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
            "    for line in lines:\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
            "    for segment in segments:\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
            "    renderable = rich_cast(renderable)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
            "    renderable = cast_method()\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
            "    pip_cmd = get_best_invocation_for_this_pip()\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
            "    if found_executable and os.path.samefile(\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/genericpath.py\", line 101, in samefile\n",
            "    s2 = os.stat(f2)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Library/Frameworks/Python.framework/Versions/3.10/bin/pip'\n",
            "Call stack:\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/main.py\", line 70, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    self.handle_pip_version_check(options)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
            "    pip_self_version_check(session, options)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
            "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1489, in warning\n",
            "    self._log(WARNING, msg, args, **kwargs)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
            "    self.handleError(record)\n",
            "Message: '[present-rich] %s'\n",
            "Arguments: (UpgradePrompt(old='22.2.2', new='22.3.1'),)\n",
            "Requirement already satisfied: emoji in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.1.0)\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
            "    extend(render(renderable, render_options))\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
            "    for render_output in iter_render:\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
            "    for line in lines:\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
            "    for segment in segments:\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
            "    renderable = rich_cast(renderable)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
            "    renderable = cast_method()\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
            "    pip_cmd = get_best_invocation_for_this_pip()\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
            "    if found_executable and os.path.samefile(\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/genericpath.py\", line 101, in samefile\n",
            "    s2 = os.stat(f2)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Library/Frameworks/Python.framework/Versions/3.10/bin/pip'\n",
            "Call stack:\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/main.py\", line 70, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    self.handle_pip_version_check(options)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
            "    pip_self_version_check(session, options)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
            "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1489, in warning\n",
            "    self._log(WARNING, msg, args, **kwargs)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
            "    self.handleError(record)\n",
            "Message: '[present-rich] %s'\n",
            "Arguments: (UpgradePrompt(old='22.2.2', new='22.3.1'),)\n",
            "Requirement already satisfied: keras in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.11.0)\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
            "    extend(render(renderable, render_options))\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
            "    for render_output in iter_render:\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
            "    for line in lines:\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
            "    for segment in segments:\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
            "    renderable = rich_cast(renderable)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
            "    renderable = cast_method()\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
            "    pip_cmd = get_best_invocation_for_this_pip()\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
            "    if found_executable and os.path.samefile(\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/genericpath.py\", line 101, in samefile\n",
            "    s2 = os.stat(f2)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Library/Frameworks/Python.framework/Versions/3.10/bin/pip'\n",
            "Call stack:\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/main.py\", line 70, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    self.handle_pip_version_check(options)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
            "    pip_self_version_check(session, options)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
            "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1489, in warning\n",
            "    self._log(WARNING, msg, args, **kwargs)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
            "    self.handleError(record)\n",
            "Message: '[present-rich] %s'\n",
            "Arguments: (UpgradePrompt(old='22.2.2', new='22.3.1'),)\n",
            "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.11.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (1.23.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (63.2.0)\n",
            "Requirement already satisfied: packaging in /Users/syeda/Library/Python/3.10/lib/python/site-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (22.11.23)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (0.28.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/syeda/Library/Python/3.10/lib/python/site-packages (from packaging->tensorflow) (3.0.9)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.6.15.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
            "    extend(render(renderable, render_options))\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
            "    for render_output in iter_render:\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
            "    for line in lines:\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
            "    for segment in segments:\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
            "    renderable = rich_cast(renderable)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
            "    renderable = cast_method()\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
            "    pip_cmd = get_best_invocation_for_this_pip()\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
            "    if found_executable and os.path.samefile(\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/genericpath.py\", line 101, in samefile\n",
            "    s2 = os.stat(f2)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/Library/Frameworks/Python.framework/Versions/3.10/bin/pip'\n",
            "Call stack:\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/main.py\", line 70, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    self.handle_pip_version_check(options)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
            "    pip_self_version_check(session, options)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
            "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1489, in warning\n",
            "    self._log(WARNING, msg, args, **kwargs)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
            "    self.handleError(record)\n",
            "Message: '[present-rich] %s'\n",
            "Arguments: (UpgradePrompt(old='22.2.2', new='22.3.1'),)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install transformers==3.4.0\n",
        "!pip3 install emoji\n",
        "!pip3 install keras\n",
        "!pip3 install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4G26Ut1fFfx1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-11 00:56:09.920273: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaModel\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertModel\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn import metrics\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "from transformers import AdamW\n",
        "from sklearn.utils import class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cdBRQUP6Ff1P"
      },
      "outputs": [],
      "source": [
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "#torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yTmVyjTQFf7h"
      },
      "outputs": [],
      "source": [
        "# Set the maximum sequence length\n",
        "MAX_LEN = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EiAepfZiFf-E"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../bragging_data/bragging_data.csv', header=0, names=['id', 'text', 'sampling', 'round_no', 'label'])\n",
        "\n",
        "text_training = []\n",
        "text_testing = []\n",
        "label_training = []\n",
        "label_testing = []\n",
        "labels_number = []\n",
        "index_training = []\n",
        "index_testing = []\n",
        "\n",
        "text_testing_print = []\n",
        "\n",
        "texts = df.text.values\n",
        "sampling_ways = df.sampling.values\n",
        "round_nos = df.round_no.values\n",
        "labels = df.label.values\n",
        "\n",
        "for i in labels:\n",
        "    if i == \"not\":\n",
        "        labels_number.append(0)\n",
        "    else:\n",
        "        labels_number.append(1)\n",
        "\n",
        "for i in range(len(sampling_ways)):\n",
        "    if sampling_ways[i] == 'keyword':\n",
        "        index_training.append(i)\n",
        "        #text_training.append(texts[i])\n",
        "        label_training.append(labels_number[i])\n",
        "    else:\n",
        "        index_testing.append(i)\n",
        "        #text_testing.append(texts[i])\n",
        "        text_testing_print.append(texts[i])\n",
        "        label_testing.append(labels_number[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gC0YPJD2FoLG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  101  2079  1050 ...     0     0     0]\n",
            " [  101  3057  2024 ...     0     0     0]\n",
            " [  101  1045  3342 ...     0     0     0]\n",
            " ...\n",
            " [  101  1030  5310 ...     0     0     0]\n",
            " [  101  1001 15716 ...  3993  2607  2008]\n",
            " [  101  2771 12036 ...     0     0     0]]\n"
          ]
        }
      ],
      "source": [
        "texts = ['[CLS] ' + str(sentence) + ' [SEP]' for sentence in texts]\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in texts]\n",
        "\n",
        "# Use the RoBERTa tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# Pad input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype='long', truncating='post', padding='post')\n",
        "print(input_ids)\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "B8thlzjlFqy6"
      },
      "outputs": [],
      "source": [
        "mask_training = []\n",
        "mask_testing = []\n",
        "for i in index_training:\n",
        "    text_training.append(input_ids[i])\n",
        "    mask_training.append(attention_masks[i])\n",
        "for i in index_testing:\n",
        "    text_testing.append(input_ids[i])\n",
        "    mask_testing.append(attention_masks[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2YaB3oXgFvkq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3382\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [3314, 3314, 0, 3314]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [20], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m y_train \u001b[39m=\u001b[39m label_training\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(x_train))\n\u001b[0;32m----> 9\u001b[0m x_dev, x_testing, y_dev, y_testing, features_dev, features_testing, mask_dev, mask_testing \u001b[39m=\u001b[39m train_test_split(text_testing, label_testing, features_testing, mask_testing, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.8\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, stratify\u001b[39m=\u001b[39;49mlabel_testing)\n\u001b[1;32m     12\u001b[0m \u001b[39m# sklearn\u001b[39;00m\n\u001b[1;32m     13\u001b[0m weight_loss \u001b[39m=\u001b[39m class_weight\u001b[39m.\u001b[39mcompute_class_weight( class_weight \u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m'\u001b[39m, classes \u001b[39m=\u001b[39m  np\u001b[39m.\u001b[39munique(y_train), y \u001b[39m=\u001b[39m y_train)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2445\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2442\u001b[0m \u001b[39mif\u001b[39;00m n_arrays \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2443\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one array required as input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2445\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39;49marrays)\n\u001b[1;32m   2447\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[1;32m   2448\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2449\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m\n\u001b[1;32m   2450\u001b[0m )\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:433\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \n\u001b[1;32m    416\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    432\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[0;32m--> 433\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[1;32m    434\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    385\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    390\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3314, 3314, 0, 3314]"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "n_epoch = 12\n",
        "\n",
        "x_train = text_training\n",
        "y_train = label_training\n",
        "\n",
        "\n",
        "print(len(x_train))\n",
        "x_dev, x_testing, y_dev, y_testing, mask_dev, mask_testing = train_test_split(text_testing, label_testing, mask_testing, test_size=0.8, random_state=0, stratify=label_testing)\n",
        "\n",
        "# sklearn\n",
        "weight_loss = class_weight.compute_class_weight( class_weight ='balanced', classes =  np.unique(y_train), y = y_train)\n",
        "weight_loss = torch.tensor(weight_loss, dtype=torch.float32).cpu()\n",
        "\n",
        "\n",
        "# model_roberta = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2).cuda()\n",
        "model_roberta = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2).cpu()\n",
        "\n",
        "\n",
        "param_optimizer = list(model_roberta.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.weight']        \n",
        "    \n",
        "optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in model_roberta.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "        {'params': [p for n, p in model_roberta.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-6)\n",
        "criterion = nn.CrossEntropyLoss(weight=weight_loss, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n",
        "\n",
        "x_train = torch.LongTensor(x_train)\n",
        "x_dev = torch.LongTensor(x_dev)\n",
        "\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_dev = torch.LongTensor(y_dev)\n",
        "\n",
        "mask_train = torch.LongTensor(mask_training)\n",
        "mask_dev = torch.LongTensor(mask_dev)\n",
        "\n",
        "# Pack to dataLoader\n",
        "train_data = TensorDataset(x_train, mask_train, y_train)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    \n",
        "dev_data = TensorDataset(x_dev, mask_dev, y_dev)\n",
        "dev_sampler = RandomSampler(dev_data)\n",
        "dev_dataloader = DataLoader(dev_data, sampler=dev_sampler, batch_size=batch_size) \n",
        "\n",
        "# Initialize previous dev loss\n",
        "previous_valid_loss = 1000\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "    print(epoch)\n",
        "\n",
        "    # Training\n",
        "    model_roberta.train()\n",
        "\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Clear out the gradients (by default they accumulate)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Generate combined representations      \n",
        "        outputs = model_roberta(input_ids=b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        #loss = criterion(logits, b_labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # track train loss\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient\n",
        "        optimizer.step()\n",
        "        \n",
        "    train_loss = np.average(train_losses)\n",
        "    print('train loss: {}'.format(train_loss))\n",
        "\n",
        "    # Validation\n",
        "    model_roberta.eval()\n",
        "\n",
        "    predictions = []\n",
        "    targets = []\n",
        "\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in dev_dataloader:\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "      \n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Generate combined representations\n",
        "            outputs = model_roberta(input_ids=b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "            #loss = criterion(logits, b_labels)\n",
        "          \n",
        "\n",
        "        valid_losses.append(loss.item())\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        \n",
        "        labels = b_labels.to('cpu').numpy() \n",
        "\n",
        "        predictions = np.append(predictions, np.argmax(logits, axis=1))\n",
        "        targets = np.append(targets, labels) \n",
        "\n",
        "    # Calculate total dev loss \n",
        "    valid_loss = np.average(valid_losses)\n",
        "    print('valid loss: {}'.format(valid_loss))\n",
        "\n",
        "    # Calculate dev f1 of sverity\n",
        "    dev_f1 = metrics.f1_score(targets, predictions, average='macro', zero_division=1)\n",
        "    print(\"dev_f1:\", dev_f1)\n",
        "\n",
        "\n",
        "    # Save the best model based on dev lossr\n",
        "    torch.save(model_roberta, './roberta-bragging.pkl')\n",
        "    print(\"saved\")             \n",
        "  \n",
        "x_testing = torch.LongTensor(x_testing)\n",
        "y_testing = torch.LongTensor(y_testing)\n",
        "mask_testing = torch.LongTensor(mask_testing)\n",
        "    \n",
        "test_data = TensorDataset(x_testing, mask_testing, y_testing) \n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "\n",
        "# Testing\n",
        "bragging_model = torch.load('./roberta-bragging.pkl')\n",
        "\n",
        "test_predictions = []\n",
        "test_targets = []\n",
        "bragging_model.eval()\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions\n",
        "        outputs = bragging_model(input_ids=b_input_ids, attention_mask=b_input_mask)\n",
        "        logits = outputs[0]\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "    test_predictions = np.append(test_predictions, np.argmax(logits, axis=1))\n",
        "    test_targets = np.append(test_targets, labels)\n",
        "\n",
        "test_acc = metrics.accuracy_score(test_targets, test_predictions)\n",
        "test_precision = metrics.precision_score(test_targets, test_predictions, average=\"macro\", zero_division=1)\n",
        "test_recall = metrics.recall_score(test_targets, test_predictions, average=\"macro\", zero_division=1)\n",
        "test_f1 = metrics.f1_score(test_targets, test_predictions, average=\"macro\", zero_division=1)\n",
        "print(\"test_acc:\", test_acc)\n",
        "print(\"test_precision:\", test_precision)\n",
        "print(\"test_recall:\", test_recall)\n",
        "print(\"test_f1:\", test_f1)\n",
        "\n",
        "target_names = ['class 0', 'class 1']\n",
        "print(metrics.classification_report(test_targets, test_predictions, target_names=target_names))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "binary_bertwitter_liwc.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
